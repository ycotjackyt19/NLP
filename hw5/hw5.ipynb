{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39a9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "# 設定自動增長 GPU 記憶體用量\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# 設定 Keras 使用的 Session\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b0df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcfc2ae",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41050c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_path, test_path, num):\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    \n",
    "    test_input_texts = []\n",
    "    test_target_texts = []\n",
    "    \n",
    "    num_lines_train_file = sum(1 for line in open(train_path, encoding='utf-8'))\n",
    "    num_lines_test_file = sum(1 for line in open(test_path, encoding='utf-8'))\n",
    "                    \n",
    "    print(\"Read\",train_path,\"...\")\n",
    "    counter = 0\n",
    "    with open(train_path,  encoding='utf-8') as fp:\n",
    "        for json_str in fp:\n",
    "            counter = counter + 1\n",
    "            data = json.loads(json_str)\n",
    "            input_texts.append(data[\"english\"])\n",
    "            target_texts.append(data[\"chinese\"])\n",
    "            \n",
    "            '''\n",
    "            if counter%1000000==0:\n",
    "                print(\"Now processing {}/{} rows...\".format(counter, num_lines_train_file))\n",
    "            '''\n",
    "            if counter==num:\n",
    "                break\n",
    "            \n",
    "    print(\"Read\",train_path,\"finished!\")\n",
    "    \n",
    "    print(\"\\nRead\",test_path,\"...\")\n",
    "    counter = 0\n",
    "    with open(test_path,  encoding='utf-8') as fp:\n",
    "        for json_str in fp:\n",
    "            counter = counter + 1\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            if counter <= num_lines_test_file-100:\n",
    "                #input_texts.append(data[\"english\"])\n",
    "                #target_texts.append(data[\"chinese\"])\n",
    "                pass\n",
    "            else:\n",
    "                test_input_texts.append(data[\"english\"])\n",
    "                test_target_texts.append(data[\"chinese\"])\n",
    "    print(\"Read\",test_path,\"finished!\")      \n",
    "          \n",
    "    return input_texts, target_texts, test_input_texts, test_target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3de829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputTargetChars(input_texts, target_texts):\n",
    "    print(\"\\nProcessing chars...\")\n",
    "    input_characters = set()\n",
    "    target_characters = set()\n",
    "    for input_text, target_text in zip(input_texts, target_texts):\n",
    "        target_text = '\\t' + target_text + '\\n'\n",
    "        for char in input_text:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "        for char in target_text:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)\n",
    "    print(\"Processing chars finished!\")\n",
    "    return input_characters, target_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff2a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncoderDecoderData(input_texts, target_texts, encoder_input_data, decoder_input_data, decoder_target_data, input_token_index, target_token_index):\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            #print(char)\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "        for t, char in enumerate(target_text):\n",
    "            # decoder_target_data 领先 decoder_input_data by 一个时间步。\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "            if t > 0:\n",
    "                # decoder_target_data 将提前一个时间步，并且将不包含开始字符。\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "        decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "        decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
    "        \n",
    "    return  encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8499c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genModel(latent_dim, num_encoder_tokens, num_decoder_tokens):\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    \n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return model,encoder_model,decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd64f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSaveModel(model, model_path, encoder_input_data, decoder_input_data, decoder_target_data, batch_size,epochs):\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2)\n",
    "    \n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959e0e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read translation2019zh/translation2019zh_train.json ...\n",
      "Read translation2019zh/translation2019zh_train.json finished!\n",
      "\n",
      "Read translation2019zh/translation2019zh_valid.json ...\n",
      "Read translation2019zh/translation2019zh_valid.json finished!\n",
      "\n",
      "Processing chars...\n",
      "Processing chars finished!\n",
      "\n",
      "Number of samples: 2500\n",
      "Number of unique input tokens: 199\n",
      "Number of unique output tokens: 3015\n",
      "Max sequence length for inputs: 256\n",
      "Max sequence length for outputs: 120\n"
     ]
    }
   ],
   "source": [
    "train_path = 'translation2019zh/translation2019zh_train.json'\n",
    "test_path = 'translation2019zh/translation2019zh_valid.json'\n",
    "model_path = 'e2c_ep100.h5'\n",
    "num_line_read = 2500\n",
    "\n",
    "batch_size = 64 \n",
    "epochs = 500\n",
    "latent_dim = 256 \n",
    "\n",
    "input_texts, target_texts, test_input_texts, test_target_texts = preprocess(train_path,test_path, num_line_read)\n",
    "input_characters, target_characters = getInputTargetChars(input_texts, target_texts)\n",
    "input_characters = sorted(list(set(input_characters)))\n",
    "target_characters = sorted(list(set(target_characters)))\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('\\nNumber of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f8d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = getEncoderDecoderData(input_texts, target_texts, encoder_input_data, decoder_input_data, decoder_target_data, input_token_index, target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72964af1",
   "metadata": {},
   "outputs": [],
   "source": [
    " model,encoder_model,decoder_model = genModel(latent_dim, num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355a2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 18s 196ms/step - loss: 2.8966 - accuracy: 0.6898 - val_loss: 2.0964 - val_accuracy: 0.7215\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 2.1546 - accuracy: 0.7134 - val_loss: 2.0672 - val_accuracy: 0.7236\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 2.1269 - accuracy: 0.7139 - val_loss: 2.0450 - val_accuracy: 0.7238\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 2.0907 - accuracy: 0.7142 - val_loss: 2.0174 - val_accuracy: 0.7241\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 2.0497 - accuracy: 0.7150 - val_loss: 1.9478 - val_accuracy: 0.7239\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.9870 - accuracy: 0.7158 - val_loss: 2.2280 - val_accuracy: 0.7235\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 1.9760 - accuracy: 0.7178 - val_loss: 1.9036 - val_accuracy: 0.7274\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.9207 - accuracy: 0.7193 - val_loss: 1.8912 - val_accuracy: 0.7306\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 2.0793 - accuracy: 0.7087 - val_loss: 1.8693 - val_accuracy: 0.7309\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.8929 - accuracy: 0.7222 - val_loss: 1.8550 - val_accuracy: 0.7317\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 1.8988 - accuracy: 0.7230 - val_loss: 1.8527 - val_accuracy: 0.7333\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 1.8674 - accuracy: 0.7248 - val_loss: 1.8365 - val_accuracy: 0.7336\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.8536 - accuracy: 0.7255 - val_loss: 1.8872 - val_accuracy: 0.7312\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.8491 - accuracy: 0.7265 - val_loss: 1.8150 - val_accuracy: 0.7357\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.8224 - accuracy: 0.7286 - val_loss: 1.8081 - val_accuracy: 0.7362\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.8070 - accuracy: 0.7297 - val_loss: 1.7977 - val_accuracy: 0.7385\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.7873 - accuracy: 0.7311 - val_loss: 1.7866 - val_accuracy: 0.7394\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.7675 - accuracy: 0.7329 - val_loss: 1.7721 - val_accuracy: 0.7394\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 1.7472 - accuracy: 0.7343 - val_loss: 1.7643 - val_accuracy: 0.7416\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.7274 - accuracy: 0.7356 - val_loss: 1.7463 - val_accuracy: 0.7427\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.7081 - accuracy: 0.7375 - val_loss: 1.7341 - val_accuracy: 0.7440\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 1.7558 - accuracy: 0.7211 - val_loss: 1.7246 - val_accuracy: 0.7449\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.6663 - accuracy: 0.7415 - val_loss: 1.7178 - val_accuracy: 0.7451\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 1.6499 - accuracy: 0.7426 - val_loss: 1.7054 - val_accuracy: 0.7476\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 1.6346 - accuracy: 0.7437 - val_loss: 1.7045 - val_accuracy: 0.7459\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 1.6162 - accuracy: 0.7455 - val_loss: 1.6992 - val_accuracy: 0.7475\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.5957 - accuracy: 0.7466 - val_loss: 1.6917 - val_accuracy: 0.7484\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.5788 - accuracy: 0.7484 - val_loss: 1.6826 - val_accuracy: 0.7499\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.5590 - accuracy: 0.7501 - val_loss: 1.6703 - val_accuracy: 0.7506\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.5414 - accuracy: 0.7517 - val_loss: 1.6649 - val_accuracy: 0.7510\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.5234 - accuracy: 0.7531 - val_loss: 1.6637 - val_accuracy: 0.7518\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.5052 - accuracy: 0.7547 - val_loss: 1.6636 - val_accuracy: 0.7523\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.4872 - accuracy: 0.7561 - val_loss: 1.6575 - val_accuracy: 0.7528\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.4702 - accuracy: 0.7575 - val_loss: 1.6543 - val_accuracy: 0.7529\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.4520 - accuracy: 0.7589 - val_loss: 1.6527 - val_accuracy: 0.7532\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 1.4352 - accuracy: 0.7608 - val_loss: 1.6524 - val_accuracy: 0.7530\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.4164 - accuracy: 0.7620 - val_loss: 1.6550 - val_accuracy: 0.7532\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.3998 - accuracy: 0.7638 - val_loss: 1.6589 - val_accuracy: 0.7526\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.3834 - accuracy: 0.7651 - val_loss: 1.6494 - val_accuracy: 0.7546\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.3641 - accuracy: 0.7669 - val_loss: 1.6421 - val_accuracy: 0.7553\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.3477 - accuracy: 0.7683 - val_loss: 1.6520 - val_accuracy: 0.7552\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.3306 - accuracy: 0.7698 - val_loss: 1.6506 - val_accuracy: 0.7545\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.3130 - accuracy: 0.7714 - val_loss: 1.6578 - val_accuracy: 0.7545\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.2965 - accuracy: 0.7731 - val_loss: 1.6591 - val_accuracy: 0.7541\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.2801 - accuracy: 0.7748 - val_loss: 1.6568 - val_accuracy: 0.7548\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 1.2623 - accuracy: 0.7763 - val_loss: 1.6591 - val_accuracy: 0.7550\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.2459 - accuracy: 0.7780 - val_loss: 1.6864 - val_accuracy: 0.7525\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.2307 - accuracy: 0.7792 - val_loss: 1.6706 - val_accuracy: 0.7543\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.2116 - accuracy: 0.7811 - val_loss: 1.6615 - val_accuracy: 0.7557\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 1.1957 - accuracy: 0.7828 - val_loss: 1.6743 - val_accuracy: 0.7543\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.1793 - accuracy: 0.7847 - val_loss: 1.6710 - val_accuracy: 0.7544\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.1631 - accuracy: 0.7864 - val_loss: 1.6756 - val_accuracy: 0.7551\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.1475 - accuracy: 0.7879 - val_loss: 1.6816 - val_accuracy: 0.7540\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.1313 - accuracy: 0.7899 - val_loss: 1.6783 - val_accuracy: 0.7542\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 1.1137 - accuracy: 0.7915 - val_loss: 1.6847 - val_accuracy: 0.7550\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 1.1000 - accuracy: 0.7934 - val_loss: 1.6897 - val_accuracy: 0.7543\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 1.0832 - accuracy: 0.7954 - val_loss: 1.6944 - val_accuracy: 0.7557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 1.0665 - accuracy: 0.7975 - val_loss: 1.6999 - val_accuracy: 0.7545\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 1.0528 - accuracy: 0.7993 - val_loss: 1.7075 - val_accuracy: 0.7539\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 1.0365 - accuracy: 0.8010 - val_loss: 1.7159 - val_accuracy: 0.7536\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 1.0209 - accuracy: 0.8036 - val_loss: 1.7186 - val_accuracy: 0.7537\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 1.0065 - accuracy: 0.8054 - val_loss: 1.7211 - val_accuracy: 0.7540\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9920 - accuracy: 0.8077 - val_loss: 1.7284 - val_accuracy: 0.7544\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.9764 - accuracy: 0.8098 - val_loss: 1.7500 - val_accuracy: 0.7522\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.9625 - accuracy: 0.8119 - val_loss: 1.7487 - val_accuracy: 0.7527\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.9477 - accuracy: 0.8145 - val_loss: 1.7424 - val_accuracy: 0.7534\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.9327 - accuracy: 0.8160 - val_loss: 1.7526 - val_accuracy: 0.7529\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.9186 - accuracy: 0.8183 - val_loss: 1.7745 - val_accuracy: 0.7510\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9046 - accuracy: 0.8205 - val_loss: 1.7642 - val_accuracy: 0.7523\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.8900 - accuracy: 0.8230 - val_loss: 1.7746 - val_accuracy: 0.7522\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.8760 - accuracy: 0.8249 - val_loss: 1.7758 - val_accuracy: 0.7520\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.8633 - accuracy: 0.8272 - val_loss: 1.7924 - val_accuracy: 0.7510\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.8505 - accuracy: 0.8290 - val_loss: 1.7876 - val_accuracy: 0.7516\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.8367 - accuracy: 0.8315 - val_loss: 1.7971 - val_accuracy: 0.7524\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.8231 - accuracy: 0.8336 - val_loss: 1.8011 - val_accuracy: 0.7526\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.8086 - accuracy: 0.8364 - val_loss: 1.8199 - val_accuracy: 0.7514\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7994 - accuracy: 0.8376 - val_loss: 1.8143 - val_accuracy: 0.7513\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7843 - accuracy: 0.8407 - val_loss: 1.8210 - val_accuracy: 0.7512\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7723 - accuracy: 0.8429 - val_loss: 1.8220 - val_accuracy: 0.7517\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7570 - accuracy: 0.8459 - val_loss: 1.8363 - val_accuracy: 0.7501\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.7484 - accuracy: 0.8472 - val_loss: 1.8501 - val_accuracy: 0.7494\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.7346 - accuracy: 0.8498 - val_loss: 1.8533 - val_accuracy: 0.7506\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7239 - accuracy: 0.8516 - val_loss: 1.8635 - val_accuracy: 0.7497\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7110 - accuracy: 0.8544 - val_loss: 1.8701 - val_accuracy: 0.7502\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7000 - accuracy: 0.8563 - val_loss: 1.8716 - val_accuracy: 0.7504\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.6871 - accuracy: 0.8590 - val_loss: 1.8887 - val_accuracy: 0.7491\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.6776 - accuracy: 0.8608 - val_loss: 1.8989 - val_accuracy: 0.7488\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.6651 - accuracy: 0.8633 - val_loss: 1.9130 - val_accuracy: 0.7487\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.6551 - accuracy: 0.8650 - val_loss: 1.9028 - val_accuracy: 0.7488\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.6423 - accuracy: 0.8681 - val_loss: 1.9112 - val_accuracy: 0.7495\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.6328 - accuracy: 0.8695 - val_loss: 1.9245 - val_accuracy: 0.7496\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.6220 - accuracy: 0.8715 - val_loss: 1.9388 - val_accuracy: 0.7487\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.6119 - accuracy: 0.8740 - val_loss: 1.9399 - val_accuracy: 0.7491\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.6028 - accuracy: 0.8759 - val_loss: 1.9422 - val_accuracy: 0.7483\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.5899 - accuracy: 0.8786 - val_loss: 1.9567 - val_accuracy: 0.7480\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.5825 - accuracy: 0.8800 - val_loss: 1.9647 - val_accuracy: 0.7491\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.5718 - accuracy: 0.8823 - val_loss: 1.9626 - val_accuracy: 0.7476\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.5624 - accuracy: 0.8842 - val_loss: 1.9827 - val_accuracy: 0.7475\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.5509 - accuracy: 0.8869 - val_loss: 1.9810 - val_accuracy: 0.7483\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.5430 - accuracy: 0.8888 - val_loss: 1.9937 - val_accuracy: 0.7475\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.5335 - accuracy: 0.8906 - val_loss: 2.0068 - val_accuracy: 0.7483\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.5245 - accuracy: 0.8922 - val_loss: 2.0050 - val_accuracy: 0.7473\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.5150 - accuracy: 0.8948 - val_loss: 2.0104 - val_accuracy: 0.7481\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.5062 - accuracy: 0.8969 - val_loss: 2.0341 - val_accuracy: 0.7469\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.4956 - accuracy: 0.8993 - val_loss: 2.0321 - val_accuracy: 0.7464\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.4886 - accuracy: 0.9004 - val_loss: 2.0444 - val_accuracy: 0.7465\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4800 - accuracy: 0.9025 - val_loss: 2.0454 - val_accuracy: 0.7463\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.4715 - accuracy: 0.9045 - val_loss: 2.0552 - val_accuracy: 0.7462\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.4633 - accuracy: 0.9065 - val_loss: 2.0647 - val_accuracy: 0.7471\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.4535 - accuracy: 0.9086 - val_loss: 2.0770 - val_accuracy: 0.7461\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.4449 - accuracy: 0.9105 - val_loss: 2.0858 - val_accuracy: 0.7462\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.4389 - accuracy: 0.9119 - val_loss: 2.0884 - val_accuracy: 0.7465\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.4312 - accuracy: 0.9140 - val_loss: 2.1118 - val_accuracy: 0.7462\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.4236 - accuracy: 0.9153 - val_loss: 2.0983 - val_accuracy: 0.7459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4149 - accuracy: 0.9178 - val_loss: 2.1233 - val_accuracy: 0.7452\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.4068 - accuracy: 0.9196 - val_loss: 2.1362 - val_accuracy: 0.7446\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3997 - accuracy: 0.9209 - val_loss: 2.1354 - val_accuracy: 0.7448\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3937 - accuracy: 0.9226 - val_loss: 2.1301 - val_accuracy: 0.7463\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3866 - accuracy: 0.9241 - val_loss: 2.1512 - val_accuracy: 0.7456\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3777 - accuracy: 0.9267 - val_loss: 2.1566 - val_accuracy: 0.7457\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.3733 - accuracy: 0.9268 - val_loss: 2.1658 - val_accuracy: 0.7445\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3632 - accuracy: 0.9300 - val_loss: 2.1708 - val_accuracy: 0.7437\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3576 - accuracy: 0.9313 - val_loss: 2.2041 - val_accuracy: 0.7445\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3525 - accuracy: 0.9316 - val_loss: 2.2021 - val_accuracy: 0.7448\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3436 - accuracy: 0.9347 - val_loss: 2.2105 - val_accuracy: 0.7439\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3384 - accuracy: 0.9359 - val_loss: 2.2141 - val_accuracy: 0.7445\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3329 - accuracy: 0.9365 - val_loss: 2.2233 - val_accuracy: 0.7449\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.3238 - accuracy: 0.9391 - val_loss: 2.2266 - val_accuracy: 0.7442\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3176 - accuracy: 0.9406 - val_loss: 2.2466 - val_accuracy: 0.7446\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3138 - accuracy: 0.9414 - val_loss: 2.2326 - val_accuracy: 0.7436\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3072 - accuracy: 0.9426 - val_loss: 2.2460 - val_accuracy: 0.7434\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3026 - accuracy: 0.9435 - val_loss: 2.2633 - val_accuracy: 0.7443\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.2938 - accuracy: 0.9456 - val_loss: 2.2690 - val_accuracy: 0.7427\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.2900 - accuracy: 0.9466 - val_loss: 2.2854 - val_accuracy: 0.7446\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.2856 - accuracy: 0.9475 - val_loss: 2.3058 - val_accuracy: 0.7437\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.2802 - accuracy: 0.9489 - val_loss: 2.2925 - val_accuracy: 0.7445\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.2731 - accuracy: 0.9502 - val_loss: 2.3110 - val_accuracy: 0.7435\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.2665 - accuracy: 0.9522 - val_loss: 2.3348 - val_accuracy: 0.7440\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.2635 - accuracy: 0.9523 - val_loss: 2.3278 - val_accuracy: 0.7427\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.2582 - accuracy: 0.9539 - val_loss: 2.3318 - val_accuracy: 0.7426\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.2529 - accuracy: 0.9550 - val_loss: 2.3296 - val_accuracy: 0.7446\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.2474 - accuracy: 0.9562 - val_loss: 2.3567 - val_accuracy: 0.7423\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.2437 - accuracy: 0.9570 - val_loss: 2.3649 - val_accuracy: 0.7430\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.2392 - accuracy: 0.9577 - val_loss: 2.3732 - val_accuracy: 0.7426\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.2338 - accuracy: 0.9593 - val_loss: 2.3756 - val_accuracy: 0.7420\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.2275 - accuracy: 0.9608 - val_loss: 2.3973 - val_accuracy: 0.7440\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.2265 - accuracy: 0.9608 - val_loss: 2.3840 - val_accuracy: 0.7428\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.2190 - accuracy: 0.9625 - val_loss: 2.4001 - val_accuracy: 0.7428\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.2157 - accuracy: 0.9632 - val_loss: 2.4126 - val_accuracy: 0.7425\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.2130 - accuracy: 0.9637 - val_loss: 2.4028 - val_accuracy: 0.7423\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.2063 - accuracy: 0.9653 - val_loss: 2.4289 - val_accuracy: 0.7424\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.2037 - accuracy: 0.9657 - val_loss: 2.4448 - val_accuracy: 0.7431\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.1984 - accuracy: 0.9672 - val_loss: 2.4515 - val_accuracy: 0.7421\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.1972 - accuracy: 0.9671 - val_loss: 2.4530 - val_accuracy: 0.7413\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1926 - accuracy: 0.9679 - val_loss: 2.4589 - val_accuracy: 0.7432\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.1853 - accuracy: 0.9702 - val_loss: 2.4774 - val_accuracy: 0.7418\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.1830 - accuracy: 0.9703 - val_loss: 2.4923 - val_accuracy: 0.7417\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.1812 - accuracy: 0.9703 - val_loss: 2.4774 - val_accuracy: 0.7422\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.1746 - accuracy: 0.9720 - val_loss: 2.4936 - val_accuracy: 0.7426\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1733 - accuracy: 0.9725 - val_loss: 2.4989 - val_accuracy: 0.7426\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.1699 - accuracy: 0.9727 - val_loss: 2.5201 - val_accuracy: 0.7426\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1650 - accuracy: 0.9740 - val_loss: 2.5209 - val_accuracy: 0.7418\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.1624 - accuracy: 0.9742 - val_loss: 2.5242 - val_accuracy: 0.7426\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.1589 - accuracy: 0.9752 - val_loss: 2.5361 - val_accuracy: 0.7417\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1565 - accuracy: 0.9756 - val_loss: 2.5468 - val_accuracy: 0.7428\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.1541 - accuracy: 0.9759 - val_loss: 2.5497 - val_accuracy: 0.7422\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1495 - accuracy: 0.9770 - val_loss: 2.5640 - val_accuracy: 0.7418\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1458 - accuracy: 0.9777 - val_loss: 2.5656 - val_accuracy: 0.7412\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.1447 - accuracy: 0.9780 - val_loss: 2.5786 - val_accuracy: 0.7412\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.1407 - accuracy: 0.9788 - val_loss: 2.5956 - val_accuracy: 0.7417\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1399 - accuracy: 0.9785 - val_loss: 2.5925 - val_accuracy: 0.7421\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1342 - accuracy: 0.9799 - val_loss: 2.5956 - val_accuracy: 0.7417\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.1359 - accuracy: 0.9792 - val_loss: 2.6101 - val_accuracy: 0.7417\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.1283 - accuracy: 0.9810 - val_loss: 2.6152 - val_accuracy: 0.7409\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.1271 - accuracy: 0.9812 - val_loss: 2.6415 - val_accuracy: 0.7420\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1247 - accuracy: 0.9814 - val_loss: 2.6362 - val_accuracy: 0.7413\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.1237 - accuracy: 0.9815 - val_loss: 2.6456 - val_accuracy: 0.7416\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.1205 - accuracy: 0.9822 - val_loss: 2.6548 - val_accuracy: 0.7404\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.1185 - accuracy: 0.9824 - val_loss: 2.6534 - val_accuracy: 0.7414\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.1150 - accuracy: 0.9832 - val_loss: 2.6618 - val_accuracy: 0.7417\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1133 - accuracy: 0.9833 - val_loss: 2.6743 - val_accuracy: 0.7415\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.1118 - accuracy: 0.9836 - val_loss: 2.6628 - val_accuracy: 0.7412\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.1081 - accuracy: 0.9842 - val_loss: 2.6783 - val_accuracy: 0.7402\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.1084 - accuracy: 0.9839 - val_loss: 2.6909 - val_accuracy: 0.7417\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.1041 - accuracy: 0.9848 - val_loss: 2.7229 - val_accuracy: 0.7406\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.1034 - accuracy: 0.9847 - val_loss: 2.7095 - val_accuracy: 0.7401\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.0998 - accuracy: 0.9854 - val_loss: 2.7120 - val_accuracy: 0.7407\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0980 - accuracy: 0.9856 - val_loss: 2.7455 - val_accuracy: 0.7416\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0987 - accuracy: 0.9853 - val_loss: 2.7226 - val_accuracy: 0.7413\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.0952 - accuracy: 0.9862 - val_loss: 2.7354 - val_accuracy: 0.7414\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0917 - accuracy: 0.9869 - val_loss: 2.7744 - val_accuracy: 0.7403\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0938 - accuracy: 0.9858 - val_loss: 2.7472 - val_accuracy: 0.7408\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0886 - accuracy: 0.9870 - val_loss: 2.7772 - val_accuracy: 0.7415\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0881 - accuracy: 0.9870 - val_loss: 2.7637 - val_accuracy: 0.7404\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0867 - accuracy: 0.9872 - val_loss: 2.7614 - val_accuracy: 0.7418\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0863 - accuracy: 0.9870 - val_loss: 2.7747 - val_accuracy: 0.7409\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0835 - accuracy: 0.9875 - val_loss: 2.7909 - val_accuracy: 0.7413\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0807 - accuracy: 0.9879 - val_loss: 2.8159 - val_accuracy: 0.7408\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0825 - accuracy: 0.9874 - val_loss: 2.7921 - val_accuracy: 0.7412\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0793 - accuracy: 0.9880 - val_loss: 2.8226 - val_accuracy: 0.7407\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0766 - accuracy: 0.9885 - val_loss: 2.8324 - val_accuracy: 0.7416\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0757 - accuracy: 0.9885 - val_loss: 2.8402 - val_accuracy: 0.7395\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0757 - accuracy: 0.9884 - val_loss: 2.8302 - val_accuracy: 0.7415\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0728 - accuracy: 0.9890 - val_loss: 2.8097 - val_accuracy: 0.7405\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0726 - accuracy: 0.9889 - val_loss: 2.8276 - val_accuracy: 0.7410\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0727 - accuracy: 0.9887 - val_loss: 2.8632 - val_accuracy: 0.7399\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0686 - accuracy: 0.9896 - val_loss: 2.8721 - val_accuracy: 0.7404\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0698 - accuracy: 0.9893 - val_loss: 2.8584 - val_accuracy: 0.7415\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0678 - accuracy: 0.9895 - val_loss: 2.8844 - val_accuracy: 0.7401\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0665 - accuracy: 0.9895 - val_loss: 2.8795 - val_accuracy: 0.7414\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0659 - accuracy: 0.9897 - val_loss: 2.8799 - val_accuracy: 0.7405\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0659 - accuracy: 0.9894 - val_loss: 2.8839 - val_accuracy: 0.7411\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0611 - accuracy: 0.9906 - val_loss: 2.8866 - val_accuracy: 0.7409\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0622 - accuracy: 0.9903 - val_loss: 2.8913 - val_accuracy: 0.7414\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0622 - accuracy: 0.9899 - val_loss: 2.9107 - val_accuracy: 0.7400\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0590 - accuracy: 0.9906 - val_loss: 2.9140 - val_accuracy: 0.7416\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0615 - accuracy: 0.9899 - val_loss: 2.9228 - val_accuracy: 0.7411\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0558 - accuracy: 0.9911 - val_loss: 2.9253 - val_accuracy: 0.7408\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0594 - accuracy: 0.9901 - val_loss: 2.9388 - val_accuracy: 0.7403\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0564 - accuracy: 0.9906 - val_loss: 2.9486 - val_accuracy: 0.7389\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0592 - accuracy: 0.9896 - val_loss: 2.9170 - val_accuracy: 0.7413\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0551 - accuracy: 0.9907 - val_loss: 2.9347 - val_accuracy: 0.7408\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0546 - accuracy: 0.9905 - val_loss: 2.9548 - val_accuracy: 0.7398\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0505 - accuracy: 0.9915 - val_loss: 2.9763 - val_accuracy: 0.7410\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0519 - accuracy: 0.9912 - val_loss: 2.9835 - val_accuracy: 0.7407\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0550 - accuracy: 0.9902 - val_loss: 2.9720 - val_accuracy: 0.7400\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0498 - accuracy: 0.9915 - val_loss: 2.9701 - val_accuracy: 0.7401\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0512 - accuracy: 0.9910 - val_loss: 2.9891 - val_accuracy: 0.7416\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0497 - accuracy: 0.9912 - val_loss: 2.9983 - val_accuracy: 0.7409\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0483 - accuracy: 0.9913 - val_loss: 3.0198 - val_accuracy: 0.7413\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0498 - accuracy: 0.9907 - val_loss: 3.0270 - val_accuracy: 0.7391\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0484 - accuracy: 0.9907 - val_loss: 3.0273 - val_accuracy: 0.7402\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0484 - accuracy: 0.9910 - val_loss: 3.0251 - val_accuracy: 0.7399\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.0468 - accuracy: 0.9911 - val_loss: 3.0338 - val_accuracy: 0.7402\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0481 - accuracy: 0.9907 - val_loss: 3.0266 - val_accuracy: 0.7416\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0450 - accuracy: 0.9915 - val_loss: 3.0532 - val_accuracy: 0.7394\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0494 - accuracy: 0.9904 - val_loss: 3.0305 - val_accuracy: 0.7402\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0416 - accuracy: 0.9920 - val_loss: 3.0581 - val_accuracy: 0.7399\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0448 - accuracy: 0.9911 - val_loss: 3.0537 - val_accuracy: 0.7401\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0439 - accuracy: 0.9911 - val_loss: 3.0758 - val_accuracy: 0.7409\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0430 - accuracy: 0.9916 - val_loss: 3.0779 - val_accuracy: 0.7402\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0433 - accuracy: 0.9915 - val_loss: 3.0728 - val_accuracy: 0.7395\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0434 - accuracy: 0.9912 - val_loss: 3.0666 - val_accuracy: 0.7397\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0422 - accuracy: 0.9918 - val_loss: 3.0566 - val_accuracy: 0.7409\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0425 - accuracy: 0.9915 - val_loss: 3.0549 - val_accuracy: 0.7407\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0404 - accuracy: 0.9917 - val_loss: 3.0740 - val_accuracy: 0.7401\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0400 - accuracy: 0.9919 - val_loss: 3.0973 - val_accuracy: 0.7401\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0406 - accuracy: 0.9916 - val_loss: 3.0913 - val_accuracy: 0.7402\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0390 - accuracy: 0.9918 - val_loss: 3.1372 - val_accuracy: 0.7389\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.0403 - accuracy: 0.9912 - val_loss: 3.0987 - val_accuracy: 0.7396\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0374 - accuracy: 0.9922 - val_loss: 3.1314 - val_accuracy: 0.7396\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0435 - accuracy: 0.9905 - val_loss: 3.1103 - val_accuracy: 0.7405\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 3.1104 - val_accuracy: 0.7410\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0378 - accuracy: 0.9917 - val_loss: 3.0859 - val_accuracy: 0.7416\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.0379 - accuracy: 0.9917 - val_loss: 3.1379 - val_accuracy: 0.7403\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0408 - accuracy: 0.9912 - val_loss: 3.1149 - val_accuracy: 0.7405\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0359 - accuracy: 0.9921 - val_loss: 3.1245 - val_accuracy: 0.7399\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0351 - accuracy: 0.9922 - val_loss: 3.1419 - val_accuracy: 0.7400\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.0370 - accuracy: 0.9916 - val_loss: 3.1496 - val_accuracy: 0.7411\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0367 - accuracy: 0.9915 - val_loss: 3.1569 - val_accuracy: 0.7398\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0370 - accuracy: 0.9916 - val_loss: 3.1532 - val_accuracy: 0.7404\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0357 - accuracy: 0.9919 - val_loss: 3.1544 - val_accuracy: 0.7400\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0363 - accuracy: 0.9917 - val_loss: 3.1633 - val_accuracy: 0.7398\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0357 - accuracy: 0.9918 - val_loss: 3.1673 - val_accuracy: 0.7404\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0345 - accuracy: 0.9920 - val_loss: 3.1791 - val_accuracy: 0.7400\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0356 - accuracy: 0.9919 - val_loss: 3.1701 - val_accuracy: 0.7405\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 3.1790 - val_accuracy: 0.7408\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0350 - accuracy: 0.9919 - val_loss: 3.1802 - val_accuracy: 0.7406\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0358 - accuracy: 0.9913 - val_loss: 3.1696 - val_accuracy: 0.7409\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 3.1807 - val_accuracy: 0.7405\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0343 - accuracy: 0.9916 - val_loss: 3.1846 - val_accuracy: 0.7402\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0338 - accuracy: 0.9918 - val_loss: 3.1925 - val_accuracy: 0.7403\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0339 - accuracy: 0.9918 - val_loss: 3.1855 - val_accuracy: 0.7411\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 3.2251 - val_accuracy: 0.7398\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 3.1948 - val_accuracy: 0.7406\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 3.1933 - val_accuracy: 0.7403\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0311 - accuracy: 0.9922 - val_loss: 3.2185 - val_accuracy: 0.7401\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 3.2373 - val_accuracy: 0.7400\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0335 - accuracy: 0.9914 - val_loss: 3.2221 - val_accuracy: 0.7410\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0315 - accuracy: 0.9922 - val_loss: 3.2150 - val_accuracy: 0.7417\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0331 - accuracy: 0.9917 - val_loss: 3.2203 - val_accuracy: 0.7404\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0325 - accuracy: 0.9917 - val_loss: 3.2272 - val_accuracy: 0.7412\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 3.2319 - val_accuracy: 0.7412\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 3.2455 - val_accuracy: 0.7403\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 3.2581 - val_accuracy: 0.7408\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 3.2423 - val_accuracy: 0.7401\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 3.2390 - val_accuracy: 0.7408\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0295 - accuracy: 0.9922 - val_loss: 3.2368 - val_accuracy: 0.7412\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0305 - accuracy: 0.9921 - val_loss: 3.2518 - val_accuracy: 0.7403\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 3.2557 - val_accuracy: 0.7404\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0297 - accuracy: 0.9922 - val_loss: 3.2646 - val_accuracy: 0.7399\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0294 - accuracy: 0.9923 - val_loss: 3.2845 - val_accuracy: 0.7402\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0313 - accuracy: 0.9917 - val_loss: 3.2623 - val_accuracy: 0.7404\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0310 - accuracy: 0.9919 - val_loss: 3.2643 - val_accuracy: 0.7412\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 3.2763 - val_accuracy: 0.7412\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 3.2666 - val_accuracy: 0.7405\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 3.2809 - val_accuracy: 0.7404\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 3.2697 - val_accuracy: 0.7401\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0310 - accuracy: 0.9916 - val_loss: 3.2936 - val_accuracy: 0.7408\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 3.2760 - val_accuracy: 0.7413\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 3.2673 - val_accuracy: 0.7409\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 3.3037 - val_accuracy: 0.7408\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 3.3067 - val_accuracy: 0.7396\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 3.2940 - val_accuracy: 0.7410\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 3.2899 - val_accuracy: 0.7412\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 3.2921 - val_accuracy: 0.7414\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 3.3025 - val_accuracy: 0.7400\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 3.3061 - val_accuracy: 0.7400\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 3.3146 - val_accuracy: 0.7409\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0277 - accuracy: 0.9922 - val_loss: 3.2988 - val_accuracy: 0.7413\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0288 - accuracy: 0.9919 - val_loss: 3.3125 - val_accuracy: 0.7406\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 3.3018 - val_accuracy: 0.7402\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 3.3178 - val_accuracy: 0.7415\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0292 - accuracy: 0.9919 - val_loss: 3.3078 - val_accuracy: 0.7416\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 3.3219 - val_accuracy: 0.7414\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 3.3157 - val_accuracy: 0.7419\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 3.3177 - val_accuracy: 0.7411\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 3.3289 - val_accuracy: 0.7414\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 3.3308 - val_accuracy: 0.7409\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 3.3381 - val_accuracy: 0.7408\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 3.3235 - val_accuracy: 0.7411\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 3.3109 - val_accuracy: 0.7414\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 3.3402 - val_accuracy: 0.7413\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 3.3378 - val_accuracy: 0.7409\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 3.3516 - val_accuracy: 0.7407\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 3.3495 - val_accuracy: 0.7420\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 3.3504 - val_accuracy: 0.7411\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 3.3619 - val_accuracy: 0.7409\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 3.3447 - val_accuracy: 0.7412\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 3.3679 - val_accuracy: 0.7409\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 3.3382 - val_accuracy: 0.7416\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 3.3808 - val_accuracy: 0.7415\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 3.3830 - val_accuracy: 0.7420\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 3.3595 - val_accuracy: 0.7415\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 3.3736 - val_accuracy: 0.7419\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 3.4127 - val_accuracy: 0.7401\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 3.3657 - val_accuracy: 0.7416\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 3.3720 - val_accuracy: 0.7410\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 3.3976 - val_accuracy: 0.7418\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 3.3684 - val_accuracy: 0.7413\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 3.3934 - val_accuracy: 0.7414\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0272 - accuracy: 0.9918 - val_loss: 3.3860 - val_accuracy: 0.7411\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 3.3758 - val_accuracy: 0.7407\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 3.3880 - val_accuracy: 0.7414\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0272 - accuracy: 0.9918 - val_loss: 3.3926 - val_accuracy: 0.7416\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 3.3779 - val_accuracy: 0.7414\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 3.3934 - val_accuracy: 0.7413\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 3.3863 - val_accuracy: 0.7415\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 3.3832 - val_accuracy: 0.7406\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 3.3874 - val_accuracy: 0.7415\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 3.4090 - val_accuracy: 0.7412\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 3.4015 - val_accuracy: 0.7422\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 3.4011 - val_accuracy: 0.7416\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 3.4032 - val_accuracy: 0.7415\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 3.4261 - val_accuracy: 0.7410\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 3.4061 - val_accuracy: 0.7413\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 3.4210 - val_accuracy: 0.7419\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 3.4374 - val_accuracy: 0.7417\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 3.4328 - val_accuracy: 0.7417\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 3.4229 - val_accuracy: 0.7411\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 3.4223 - val_accuracy: 0.7415\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 3.4239 - val_accuracy: 0.7414\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 3.4158 - val_accuracy: 0.7415\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 3.4277 - val_accuracy: 0.7413\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 3.4413 - val_accuracy: 0.7414\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 3.4308 - val_accuracy: 0.7418\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 3.4512 - val_accuracy: 0.7410\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 3.4281 - val_accuracy: 0.7417\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 3.4306 - val_accuracy: 0.7419\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 3.4412 - val_accuracy: 0.7417\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 3.4305 - val_accuracy: 0.7422\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 3.4316 - val_accuracy: 0.7416\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 3.4377 - val_accuracy: 0.7409\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 3.4323 - val_accuracy: 0.7419\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 3.4595 - val_accuracy: 0.7406\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 3.4436 - val_accuracy: 0.7415\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 3.4480 - val_accuracy: 0.7420\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 3.4402 - val_accuracy: 0.7424\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 3.4252 - val_accuracy: 0.7411\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 3.4470 - val_accuracy: 0.7416\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 3.4392 - val_accuracy: 0.7417\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 3.4548 - val_accuracy: 0.7421\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 3.4392 - val_accuracy: 0.7421\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 3.4461 - val_accuracy: 0.7421\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 3.4525 - val_accuracy: 0.7418\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 3.4665 - val_accuracy: 0.7416\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 3.4680 - val_accuracy: 0.7402\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 3.4567 - val_accuracy: 0.7419\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 3.4558 - val_accuracy: 0.7419\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 3.4789 - val_accuracy: 0.7413\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 3.4671 - val_accuracy: 0.7414\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 3.4853 - val_accuracy: 0.7413\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 3.4651 - val_accuracy: 0.7415\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 3.4582 - val_accuracy: 0.7426\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 3.4743 - val_accuracy: 0.7414\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 3.4701 - val_accuracy: 0.7423\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 3.4779 - val_accuracy: 0.7413\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 3.4929 - val_accuracy: 0.7420\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 3.4833 - val_accuracy: 0.7418\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 3.4858 - val_accuracy: 0.7419\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 3.4606 - val_accuracy: 0.7420\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 3.4753 - val_accuracy: 0.7419\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 3.5034 - val_accuracy: 0.7422\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 3.4822 - val_accuracy: 0.7415\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 3.4974 - val_accuracy: 0.7418\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 3.4894 - val_accuracy: 0.7418\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 3.4933 - val_accuracy: 0.7417\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 3.4912 - val_accuracy: 0.7417\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 3.4957 - val_accuracy: 0.7413\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 3.4913 - val_accuracy: 0.7419\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 3.4855 - val_accuracy: 0.7421\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 3.5021 - val_accuracy: 0.7412\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 3.5278 - val_accuracy: 0.7412\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 3.4976 - val_accuracy: 0.7411\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 3.5062 - val_accuracy: 0.7421\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 3.5020 - val_accuracy: 0.7415\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 3.5104 - val_accuracy: 0.7417\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 3.4981 - val_accuracy: 0.7424\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 3.4920 - val_accuracy: 0.7414\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 3.5051 - val_accuracy: 0.7420\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 3.5240 - val_accuracy: 0.7415\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 3.5016 - val_accuracy: 0.7419\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 3.5093 - val_accuracy: 0.7414\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 3.5170 - val_accuracy: 0.7412\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 3.5207 - val_accuracy: 0.7422\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 3.5058 - val_accuracy: 0.7425\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 3.5192 - val_accuracy: 0.7421\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 3.5319 - val_accuracy: 0.7415\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 3.5156 - val_accuracy: 0.7419\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 3.5181 - val_accuracy: 0.7419\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 3.5087 - val_accuracy: 0.7423\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 3.5134 - val_accuracy: 0.7423\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 3.5305 - val_accuracy: 0.7409\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 3.5104 - val_accuracy: 0.7426\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 3.5159 - val_accuracy: 0.7415\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 3.5320 - val_accuracy: 0.7425\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 3.5126 - val_accuracy: 0.7423\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 3.5293 - val_accuracy: 0.7424\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 3.5236 - val_accuracy: 0.7423\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 3.5524 - val_accuracy: 0.7419\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 3.5252 - val_accuracy: 0.7424\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 3.5392 - val_accuracy: 0.7422\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 3.5382 - val_accuracy: 0.7416\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 3.5308 - val_accuracy: 0.7416\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 3.5290 - val_accuracy: 0.7424\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 3.5171 - val_accuracy: 0.7425\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 3.5339 - val_accuracy: 0.7430\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 3.5472 - val_accuracy: 0.7421\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 3.5384 - val_accuracy: 0.7423\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 3.5298 - val_accuracy: 0.7422\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 3.5554 - val_accuracy: 0.7419\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 3.5531 - val_accuracy: 0.7415\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 3.5390 - val_accuracy: 0.7404\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 3.5550 - val_accuracy: 0.7421\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 3.5582 - val_accuracy: 0.7422\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 3.5581 - val_accuracy: 0.7420\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.5513 - val_accuracy: 0.7422\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 3.5664 - val_accuracy: 0.7412\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 3.5599 - val_accuracy: 0.7417\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 3.5580 - val_accuracy: 0.7419\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 3.5699 - val_accuracy: 0.7421\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 3.5630 - val_accuracy: 0.7422\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 3.5592 - val_accuracy: 0.7420\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 3.5780 - val_accuracy: 0.7424\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 3.5496 - val_accuracy: 0.7416\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 3.5697 - val_accuracy: 0.7416\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 3.5504 - val_accuracy: 0.7424\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 3.5629 - val_accuracy: 0.7424\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 3.5761 - val_accuracy: 0.7421\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 3.5617 - val_accuracy: 0.7426\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 3.5729 - val_accuracy: 0.7422\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.5748 - val_accuracy: 0.7416\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.5831 - val_accuracy: 0.7426\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 3.5724 - val_accuracy: 0.7418\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 3.5757 - val_accuracy: 0.7421\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.5970 - val_accuracy: 0.7411\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 3.5924 - val_accuracy: 0.7420\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.5814 - val_accuracy: 0.7415\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 3.5869 - val_accuracy: 0.7425\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 3.5793 - val_accuracy: 0.7423\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 3.5716 - val_accuracy: 0.7421\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 3.5792 - val_accuracy: 0.7424\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 3.5725 - val_accuracy: 0.7416\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 3.5898 - val_accuracy: 0.7413\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 3.5845 - val_accuracy: 0.7427\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 3.5936 - val_accuracy: 0.7429\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.6062 - val_accuracy: 0.7426\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 3.5822 - val_accuracy: 0.7421\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 3.5997 - val_accuracy: 0.7418\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 3.5983 - val_accuracy: 0.7420\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 3.5881 - val_accuracy: 0.7424\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 3.6048 - val_accuracy: 0.7419\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 3.6066 - val_accuracy: 0.7419\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 3.5995 - val_accuracy: 0.7425\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 3.6098 - val_accuracy: 0.7421\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 3.6014 - val_accuracy: 0.7430\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 3.5984 - val_accuracy: 0.7420\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 3.6003 - val_accuracy: 0.7428\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 3.6072 - val_accuracy: 0.7422\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 3.6114 - val_accuracy: 0.7426\n"
     ]
    }
   ],
   "source": [
    "trainSaveModel(model, model_path, encoder_input_data, decoder_input_data, decoder_target_data, batch_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9451b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f9b8aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 2.3371 - accuracy: 0.7453 - val_loss: 1.8029 - val_accuracy: 0.7609\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 1.7879 - accuracy: 0.7613 - val_loss: 1.7850 - val_accuracy: 0.7615\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 1.7583 - accuracy: 0.7620 - val_loss: 1.7372 - val_accuracy: 0.7613\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 1.6979 - accuracy: 0.7626 - val_loss: 1.7101 - val_accuracy: 0.7618\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 1.6388 - accuracy: 0.7639 - val_loss: 1.6442 - val_accuracy: 0.7670\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 1.6171 - accuracy: 0.7663 - val_loss: 1.6209 - val_accuracy: 0.7673\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 1.6030 - accuracy: 0.7677 - val_loss: 1.6140 - val_accuracy: 0.7664\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 1.5909 - accuracy: 0.7698 - val_loss: 1.6331 - val_accuracy: 0.7635\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 1.5578 - accuracy: 0.7710 - val_loss: 1.5820 - val_accuracy: 0.7705\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 1.5375 - accuracy: 0.7726 - val_loss: 1.5711 - val_accuracy: 0.7715\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 1.5161 - accuracy: 0.7751 - val_loss: 1.5453 - val_accuracy: 0.7740\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 157s 3s/step - loss: 1.4887 - accuracy: 0.7769 - val_loss: 1.5302 - val_accuracy: 0.7742\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 156s 3s/step - loss: 1.4715 - accuracy: 0.7791 - val_loss: 1.5051 - val_accuracy: 0.7776\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 1.4407 - accuracy: 0.7813 - val_loss: 1.4907 - val_accuracy: 0.7789\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 1.4179 - accuracy: 0.7833 - val_loss: 1.4770 - val_accuracy: 0.7805\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 1.3945 - accuracy: 0.7853 - val_loss: 1.4582 - val_accuracy: 0.7823\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 1.3716 - accuracy: 0.7871 - val_loss: 1.4409 - val_accuracy: 0.7834\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 1.3488 - accuracy: 0.7893 - val_loss: 1.4307 - val_accuracy: 0.7848\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 1.3287 - accuracy: 0.7911 - val_loss: 1.4188 - val_accuracy: 0.7863\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 143s 3s/step - loss: 1.3080 - accuracy: 0.7932 - val_loss: 1.4165 - val_accuracy: 0.7873\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 1.2896 - accuracy: 0.7947 - val_loss: 1.4032 - val_accuracy: 0.7887\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 1.2700 - accuracy: 0.7965 - val_loss: 1.3935 - val_accuracy: 0.7897\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 1.2512 - accuracy: 0.7983 - val_loss: 1.3887 - val_accuracy: 0.7901\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 1.2337 - accuracy: 0.7998 - val_loss: 1.3841 - val_accuracy: 0.7911\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 1.2161 - accuracy: 0.8010 - val_loss: 1.3768 - val_accuracy: 0.7917\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 1.1992 - accuracy: 0.8026 - val_loss: 1.3799 - val_accuracy: 0.7920\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 1.1823 - accuracy: 0.8040 - val_loss: 1.3731 - val_accuracy: 0.7928\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 1.1663 - accuracy: 0.8054 - val_loss: 1.3690 - val_accuracy: 0.7930\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 1.1493 - accuracy: 0.8068 - val_loss: 1.3669 - val_accuracy: 0.7930\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 1.1343 - accuracy: 0.8084 - val_loss: 1.3661 - val_accuracy: 0.7931\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 1.1181 - accuracy: 0.8098 - val_loss: 1.3659 - val_accuracy: 0.7936\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 1.1025 - accuracy: 0.8111 - val_loss: 1.3651 - val_accuracy: 0.7936\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 1.0870 - accuracy: 0.8127 - val_loss: 1.3675 - val_accuracy: 0.7937\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 1.0721 - accuracy: 0.8141 - val_loss: 1.3704 - val_accuracy: 0.7939\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 1.0563 - accuracy: 0.8154 - val_loss: 1.3729 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 1.0415 - accuracy: 0.8167 - val_loss: 1.3698 - val_accuracy: 0.7940\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 1.0264 - accuracy: 0.8184 - val_loss: 1.3733 - val_accuracy: 0.7936\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 1.0120 - accuracy: 0.8198 - val_loss: 1.3771 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.9974 - accuracy: 0.8213 - val_loss: 1.3762 - val_accuracy: 0.7936\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.9831 - accuracy: 0.8228 - val_loss: 1.3842 - val_accuracy: 0.7935\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.9683 - accuracy: 0.8240 - val_loss: 1.3847 - val_accuracy: 0.7930\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.9546 - accuracy: 0.8259 - val_loss: 1.3891 - val_accuracy: 0.7930\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.9395 - accuracy: 0.8276 - val_loss: 1.3990 - val_accuracy: 0.7924\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.9266 - accuracy: 0.8288 - val_loss: 1.4025 - val_accuracy: 0.7923\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.9124 - accuracy: 0.8304 - val_loss: 1.3987 - val_accuracy: 0.7929\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.8990 - accuracy: 0.8323 - val_loss: 1.4057 - val_accuracy: 0.7924\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 143s 3s/step - loss: 0.8854 - accuracy: 0.8337 - val_loss: 1.4154 - val_accuracy: 0.7919\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.8726 - accuracy: 0.8353 - val_loss: 1.4257 - val_accuracy: 0.7916\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.8589 - accuracy: 0.8371 - val_loss: 1.4255 - val_accuracy: 0.7920\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.8464 - accuracy: 0.8385 - val_loss: 1.4281 - val_accuracy: 0.7917\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.8330 - accuracy: 0.8402 - val_loss: 1.4347 - val_accuracy: 0.7915\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.8203 - accuracy: 0.8422 - val_loss: 1.4485 - val_accuracy: 0.7904\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 143s 3s/step - loss: 0.8083 - accuracy: 0.8437 - val_loss: 1.4511 - val_accuracy: 0.7911\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.7963 - accuracy: 0.8452 - val_loss: 1.4513 - val_accuracy: 0.7908\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.7837 - accuracy: 0.8471 - val_loss: 1.4588 - val_accuracy: 0.7907\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.7726 - accuracy: 0.8490 - val_loss: 1.4664 - val_accuracy: 0.7907\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.7590 - accuracy: 0.8508 - val_loss: 1.4760 - val_accuracy: 0.7900\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.7482 - accuracy: 0.8524 - val_loss: 1.4782 - val_accuracy: 0.7899\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.7350 - accuracy: 0.8545 - val_loss: 1.4837 - val_accuracy: 0.7899\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 142s 3s/step - loss: 0.7247 - accuracy: 0.8562 - val_loss: 1.4944 - val_accuracy: 0.7891\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.7137 - accuracy: 0.8581 - val_loss: 1.5025 - val_accuracy: 0.7886\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.7015 - accuracy: 0.8601 - val_loss: 1.5045 - val_accuracy: 0.7896\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.6910 - accuracy: 0.8619 - val_loss: 1.5107 - val_accuracy: 0.7887\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.6807 - accuracy: 0.8634 - val_loss: 1.5179 - val_accuracy: 0.7888\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.6690 - accuracy: 0.8656 - val_loss: 1.5251 - val_accuracy: 0.7889\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.6601 - accuracy: 0.8672 - val_loss: 1.5344 - val_accuracy: 0.7884\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.6490 - accuracy: 0.8692 - val_loss: 1.5400 - val_accuracy: 0.7884\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 156s 3s/step - loss: 0.6379 - accuracy: 0.8709 - val_loss: 1.5467 - val_accuracy: 0.7877\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.6296 - accuracy: 0.8724 - val_loss: 1.5541 - val_accuracy: 0.7880\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.6187 - accuracy: 0.8745 - val_loss: 1.5599 - val_accuracy: 0.7873\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.6093 - accuracy: 0.8765 - val_loss: 1.5655 - val_accuracy: 0.7875\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.5994 - accuracy: 0.8780 - val_loss: 1.5748 - val_accuracy: 0.7873\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.5908 - accuracy: 0.8799 - val_loss: 1.5847 - val_accuracy: 0.7868\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 164s 3s/step - loss: 0.5809 - accuracy: 0.8819 - val_loss: 1.5975 - val_accuracy: 0.7865\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 155s 3s/step - loss: 0.5704 - accuracy: 0.8836 - val_loss: 1.5991 - val_accuracy: 0.7866\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 167s 3s/step - loss: 0.5623 - accuracy: 0.8857 - val_loss: 1.6065 - val_accuracy: 0.7863\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 163s 3s/step - loss: 0.5533 - accuracy: 0.8870 - val_loss: 1.6095 - val_accuracy: 0.7861\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 163s 3s/step - loss: 0.5439 - accuracy: 0.8887 - val_loss: 1.6234 - val_accuracy: 0.7858\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 159s 3s/step - loss: 0.5366 - accuracy: 0.8903 - val_loss: 1.6343 - val_accuracy: 0.7854\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.5265 - accuracy: 0.8926 - val_loss: 1.6332 - val_accuracy: 0.7854\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.5186 - accuracy: 0.8941 - val_loss: 1.6438 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.5106 - accuracy: 0.8956 - val_loss: 1.6491 - val_accuracy: 0.7858\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.5026 - accuracy: 0.8972 - val_loss: 1.6595 - val_accuracy: 0.7852\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.4940 - accuracy: 0.8989 - val_loss: 1.6732 - val_accuracy: 0.7848\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.4868 - accuracy: 0.9006 - val_loss: 1.6729 - val_accuracy: 0.7855\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.4777 - accuracy: 0.9030 - val_loss: 1.6786 - val_accuracy: 0.7854\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 157s 3s/step - loss: 0.4709 - accuracy: 0.9039 - val_loss: 1.6911 - val_accuracy: 0.7841\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 156s 3s/step - loss: 0.4628 - accuracy: 0.9055 - val_loss: 1.6943 - val_accuracy: 0.7850\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 161s 3s/step - loss: 0.4557 - accuracy: 0.9073 - val_loss: 1.7079 - val_accuracy: 0.7844\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 163s 3s/step - loss: 0.4475 - accuracy: 0.9089 - val_loss: 1.7160 - val_accuracy: 0.7847\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 160s 3s/step - loss: 0.4408 - accuracy: 0.9103 - val_loss: 1.7247 - val_accuracy: 0.7844\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.4332 - accuracy: 0.9118 - val_loss: 1.7334 - val_accuracy: 0.7840\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 158s 3s/step - loss: 0.4263 - accuracy: 0.9135 - val_loss: 1.7419 - val_accuracy: 0.7842\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 162s 3s/step - loss: 0.4193 - accuracy: 0.9149 - val_loss: 1.7454 - val_accuracy: 0.7844\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 162s 3s/step - loss: 0.4132 - accuracy: 0.9161 - val_loss: 1.7555 - val_accuracy: 0.7837\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 164s 3s/step - loss: 0.4059 - accuracy: 0.9182 - val_loss: 1.7575 - val_accuracy: 0.7838\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.3995 - accuracy: 0.9192 - val_loss: 1.7744 - val_accuracy: 0.7838\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.3924 - accuracy: 0.9209 - val_loss: 1.7768 - val_accuracy: 0.7837\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.3861 - accuracy: 0.9225 - val_loss: 1.7895 - val_accuracy: 0.7829\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.3790 - accuracy: 0.9241 - val_loss: 1.7952 - val_accuracy: 0.7831\n"
     ]
    }
   ],
   "source": [
    "trainSaveModel(model, model_path, encoder_input_data, decoder_input_data, decoder_target_data, batch_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b15e9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 155s 3s/step - loss: 0.3935 - accuracy: 0.9190 - val_loss: 1.7967 - val_accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.3699 - accuracy: 0.9258 - val_loss: 1.8144 - val_accuracy: 0.7832\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.3630 - accuracy: 0.9277 - val_loss: 1.8177 - val_accuracy: 0.7828\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 143s 3s/step - loss: 0.3574 - accuracy: 0.9285 - val_loss: 1.8294 - val_accuracy: 0.7827\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.3501 - accuracy: 0.9305 - val_loss: 1.8387 - val_accuracy: 0.7831\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.3449 - accuracy: 0.9318 - val_loss: 1.8434 - val_accuracy: 0.7826\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.3390 - accuracy: 0.9328 - val_loss: 1.8496 - val_accuracy: 0.7826\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.3332 - accuracy: 0.9340 - val_loss: 1.8591 - val_accuracy: 0.7826\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.3279 - accuracy: 0.9354 - val_loss: 1.8674 - val_accuracy: 0.7824\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.3221 - accuracy: 0.9364 - val_loss: 1.8722 - val_accuracy: 0.7822\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.3187 - accuracy: 0.9374 - val_loss: 1.8863 - val_accuracy: 0.7822\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.3105 - accuracy: 0.9394 - val_loss: 1.8920 - val_accuracy: 0.7817\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.3070 - accuracy: 0.9399 - val_loss: 1.9009 - val_accuracy: 0.7818\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.3015 - accuracy: 0.9409 - val_loss: 1.9030 - val_accuracy: 0.7822\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.2962 - accuracy: 0.9426 - val_loss: 1.9162 - val_accuracy: 0.7820\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.2911 - accuracy: 0.9438 - val_loss: 1.9217 - val_accuracy: 0.7819\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.2865 - accuracy: 0.9445 - val_loss: 1.9254 - val_accuracy: 0.7818\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.2822 - accuracy: 0.9454 - val_loss: 1.9440 - val_accuracy: 0.7816\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.2764 - accuracy: 0.9471 - val_loss: 1.9518 - val_accuracy: 0.7812\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.2717 - accuracy: 0.9477 - val_loss: 1.9594 - val_accuracy: 0.7813\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.2680 - accuracy: 0.9486 - val_loss: 1.9769 - val_accuracy: 0.7812\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.2636 - accuracy: 0.9497 - val_loss: 1.9742 - val_accuracy: 0.7811\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.2580 - accuracy: 0.9510 - val_loss: 1.9739 - val_accuracy: 0.7815\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.2546 - accuracy: 0.9518 - val_loss: 1.9889 - val_accuracy: 0.7810\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.2493 - accuracy: 0.9530 - val_loss: 2.0021 - val_accuracy: 0.7810\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.2463 - accuracy: 0.9535 - val_loss: 2.0045 - val_accuracy: 0.7808\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.2406 - accuracy: 0.9550 - val_loss: 2.0062 - val_accuracy: 0.7814\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.2390 - accuracy: 0.9547 - val_loss: 2.0216 - val_accuracy: 0.7809\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.2331 - accuracy: 0.9565 - val_loss: 2.0276 - val_accuracy: 0.7809\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.2308 - accuracy: 0.9568 - val_loss: 2.0322 - val_accuracy: 0.7812\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.2245 - accuracy: 0.9584 - val_loss: 2.0531 - val_accuracy: 0.7800\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.2222 - accuracy: 0.9590 - val_loss: 2.0528 - val_accuracy: 0.7812\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 143s 3s/step - loss: 0.2164 - accuracy: 0.9603 - val_loss: 2.0674 - val_accuracy: 0.7804\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.2147 - accuracy: 0.9604 - val_loss: 2.0745 - val_accuracy: 0.7807\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.2105 - accuracy: 0.9614 - val_loss: 2.0770 - val_accuracy: 0.7809\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.2073 - accuracy: 0.9623 - val_loss: 2.0843 - val_accuracy: 0.7802\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.2034 - accuracy: 0.9631 - val_loss: 2.0864 - val_accuracy: 0.7808\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1999 - accuracy: 0.9638 - val_loss: 2.1068 - val_accuracy: 0.7804\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1975 - accuracy: 0.9643 - val_loss: 2.1099 - val_accuracy: 0.7798\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.1930 - accuracy: 0.9653 - val_loss: 2.1271 - val_accuracy: 0.7800\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1916 - accuracy: 0.9653 - val_loss: 2.1241 - val_accuracy: 0.7802\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.1872 - accuracy: 0.9667 - val_loss: 2.1279 - val_accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.1835 - accuracy: 0.9675 - val_loss: 2.1336 - val_accuracy: 0.7800\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.1811 - accuracy: 0.9680 - val_loss: 2.1421 - val_accuracy: 0.7801\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.1763 - accuracy: 0.9692 - val_loss: 2.1555 - val_accuracy: 0.7799\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1739 - accuracy: 0.9694 - val_loss: 2.1607 - val_accuracy: 0.7799\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1724 - accuracy: 0.9697 - val_loss: 2.1702 - val_accuracy: 0.7796\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1689 - accuracy: 0.9706 - val_loss: 2.1910 - val_accuracy: 0.7795\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1655 - accuracy: 0.9714 - val_loss: 2.2033 - val_accuracy: 0.7795\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1633 - accuracy: 0.9715 - val_loss: 2.1896 - val_accuracy: 0.7796\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.1606 - accuracy: 0.9725 - val_loss: 2.2027 - val_accuracy: 0.7796\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1567 - accuracy: 0.9734 - val_loss: 2.2100 - val_accuracy: 0.7796\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.1552 - accuracy: 0.9734 - val_loss: 2.2144 - val_accuracy: 0.7797\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.1528 - accuracy: 0.9738 - val_loss: 2.2292 - val_accuracy: 0.7792\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.1496 - accuracy: 0.9746 - val_loss: 2.2283 - val_accuracy: 0.7795\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1472 - accuracy: 0.9751 - val_loss: 2.2398 - val_accuracy: 0.7795\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.1451 - accuracy: 0.9755 - val_loss: 2.2437 - val_accuracy: 0.7794\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.1417 - accuracy: 0.9766 - val_loss: 2.2518 - val_accuracy: 0.7794\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1399 - accuracy: 0.9767 - val_loss: 2.2615 - val_accuracy: 0.7792\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1376 - accuracy: 0.9770 - val_loss: 2.2684 - val_accuracy: 0.7798\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 145s 3s/step - loss: 0.1356 - accuracy: 0.9775 - val_loss: 2.2755 - val_accuracy: 0.7789\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.1326 - accuracy: 0.9780 - val_loss: 2.2641 - val_accuracy: 0.7792\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1307 - accuracy: 0.9786 - val_loss: 2.2796 - val_accuracy: 0.7795\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.1279 - accuracy: 0.9791 - val_loss: 2.2998 - val_accuracy: 0.7786\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1266 - accuracy: 0.9793 - val_loss: 2.3102 - val_accuracy: 0.7788\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.1246 - accuracy: 0.9796 - val_loss: 2.3186 - val_accuracy: 0.7787\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 154s 3s/step - loss: 0.1224 - accuracy: 0.9802 - val_loss: 2.3223 - val_accuracy: 0.7787\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1205 - accuracy: 0.9804 - val_loss: 2.3248 - val_accuracy: 0.7787\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 154s 3s/step - loss: 0.1181 - accuracy: 0.9808 - val_loss: 2.3321 - val_accuracy: 0.7787\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.1162 - accuracy: 0.9810 - val_loss: 2.3312 - val_accuracy: 0.7788\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1143 - accuracy: 0.9815 - val_loss: 2.3512 - val_accuracy: 0.7791\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.1122 - accuracy: 0.9821 - val_loss: 2.3557 - val_accuracy: 0.7783\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1107 - accuracy: 0.9823 - val_loss: 2.3605 - val_accuracy: 0.7789\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.1100 - accuracy: 0.9821 - val_loss: 2.3629 - val_accuracy: 0.7785\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1072 - accuracy: 0.9827 - val_loss: 2.3751 - val_accuracy: 0.7788\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.1053 - accuracy: 0.9831 - val_loss: 2.3722 - val_accuracy: 0.7787\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 154s 3s/step - loss: 0.1045 - accuracy: 0.9833 - val_loss: 2.3806 - val_accuracy: 0.7784\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 155s 3s/step - loss: 0.1019 - accuracy: 0.9837 - val_loss: 2.3955 - val_accuracy: 0.7790\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.1003 - accuracy: 0.9841 - val_loss: 2.4008 - val_accuracy: 0.7779\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.0996 - accuracy: 0.9839 - val_loss: 2.4059 - val_accuracy: 0.7788\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.0974 - accuracy: 0.9844 - val_loss: 2.4168 - val_accuracy: 0.7784\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 147s 3s/step - loss: 0.0956 - accuracy: 0.9848 - val_loss: 2.4150 - val_accuracy: 0.7782\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 148s 3s/step - loss: 0.0942 - accuracy: 0.9850 - val_loss: 2.4246 - val_accuracy: 0.7785\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.0930 - accuracy: 0.9852 - val_loss: 2.4417 - val_accuracy: 0.7790\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.0914 - accuracy: 0.9857 - val_loss: 2.4454 - val_accuracy: 0.7783\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.0894 - accuracy: 0.9859 - val_loss: 2.4461 - val_accuracy: 0.7781\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.0887 - accuracy: 0.9860 - val_loss: 2.4678 - val_accuracy: 0.7781\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.0887 - accuracy: 0.9857 - val_loss: 2.4518 - val_accuracy: 0.7785\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.0851 - accuracy: 0.9865 - val_loss: 2.4817 - val_accuracy: 0.7778\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.0844 - accuracy: 0.9866 - val_loss: 2.4793 - val_accuracy: 0.7778\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 146s 3s/step - loss: 0.0832 - accuracy: 0.9868 - val_loss: 2.4859 - val_accuracy: 0.7783\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 141s 3s/step - loss: 0.0826 - accuracy: 0.9868 - val_loss: 2.4867 - val_accuracy: 0.7781\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 142s 3s/step - loss: 0.0801 - accuracy: 0.9875 - val_loss: 2.4977 - val_accuracy: 0.7774\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 142s 3s/step - loss: 0.0792 - accuracy: 0.9875 - val_loss: 2.4963 - val_accuracy: 0.7778\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 139s 3s/step - loss: 0.0787 - accuracy: 0.9875 - val_loss: 2.5131 - val_accuracy: 0.7781\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 142s 3s/step - loss: 0.0773 - accuracy: 0.9878 - val_loss: 2.5220 - val_accuracy: 0.7780\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 138s 3s/step - loss: 0.0768 - accuracy: 0.9878 - val_loss: 2.5242 - val_accuracy: 0.7781\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 140s 3s/step - loss: 0.0751 - accuracy: 0.9879 - val_loss: 2.5192 - val_accuracy: 0.7784\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 138s 3s/step - loss: 0.0734 - accuracy: 0.9884 - val_loss: 2.5421 - val_accuracy: 0.7780\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 139s 3s/step - loss: 0.0732 - accuracy: 0.9884 - val_loss: 2.5351 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "trainSaveModel(model, model_path, encoder_input_data, decoder_input_data, decoder_target_data, batch_size,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444e495",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbddc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 将输入编码为状态向量。\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    #print(\"state:\",states_value)\n",
    "\n",
    "    # 生成长度为 1 的空目标序列。\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # 用起始字符填充目标序列的第一个字符。\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # 一批序列的采样循环\n",
    "    # (为了简化，这里我们假设一批大小为 1)。\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        #print(output_tokens)\n",
    "        # 采样一个 token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # 退出条件：达到最大长度或找到停止符。\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 更新目标序列（长度为 1）。\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 更新状态\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c3d239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向查询 token 索引可将序列解码回可读的内容。\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d252bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: For greater sharpness, but with a slight increase in graininess, you can use a 1:1 dilution of this developer.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 为了更好的锐度，但是附带的会多一些颗粒度，可以使用这个显影剂的1：1稀释液。\n",
      "-\n",
      "Input sentence: He calls the Green Book, his book of teachings, “the new gospel.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 他还把宣扬自己思想的所谓《绿皮书》称作“新福音书”。\n",
      "-\n",
      "Input sentence: And the light breeze moves me to caress her long ear\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 微风推着我去爱抚它的长耳朵\n",
      "-\n",
      "Input sentence: They have the blood of martyrs is the White to flow …\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 它们的先烈们的鲜血是白流了…\n",
      "-\n",
      "Input sentence: Finally, the Lakers head to the Motor City to take on a Pistons team that currently owns the Eastern Conference's second best record (1/31). L.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 最后，在1月31日，湖人将前往汽车城底特律挑战活塞队，活塞近来在东部排名第二。\n",
      "-\n",
      "Input sentence: \"The perfect match—my father loves names and Jackie loves money, \" sneered Alexander at the wedding. Neither he nor Christina ever got along with their stepmother17.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: “真是天造地设的一对——我父亲喜欢结交名人，杰姬酷爱金钱，”亚历山大在婚礼上讥讽道。他和克里斯蒂娜从未同他们的继母和睦相处过。\n",
      "-\n",
      "Input sentence: In 2006, Walmart was charged with racism when its recommendation engine paired Planet of the Apes with a documentary about Martin Luther King.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 2006年，沃尔玛的推荐引擎竟将《人猿星球》与马丁·路德·金的记录片配成了一对，为此沃尔玛遭到了种族歧视的指控。\n",
      "-\n",
      "Input sentence: The matte as main copper phase in the cleaning. slag was deter- mined by electron probe microscopic analysis.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 通过电子探针显微分析确定贫化渣中主要铜相为冰铜相。\n",
      "-\n",
      "Input sentence: Have you shined your shoes?\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 吉姆靠给人擦皮鞋为生。\n",
      "-\n",
      "Input sentence: The Tanning Matrix can be formed by resorcinol and oxazolidine E, and the reactioncharateristics between Tanning Matrix and collagen were investigated through NMR and size distribution analysis.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 用甘氨酸模拟胶原，研究间苯二酚-恶唑烷E鞣性基质的形成以及与胶原之间的反应特性。\n",
      "-\n",
      "Input sentence: Free delivery for addresses in the city. Can be delivered through Internet.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 免费市内取送、免费提供打印译稿及电子文档各一份。\n",
      "-\n",
      "Input sentence: Keele University is renowned for its exciting approach to higher education, beautiful campus, strong community spirit and excellent student life.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 基尔大学以其令人兴奋的方式高等教育，美丽的校园，强大的社区精神和优秀学生的生活。\n",
      "-\n",
      "Input sentence: Among them, there was the herb Tuckahoe grown in Yunnan and Guizhou provinces.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 这些中药中就有生长于云南和贵州的茯苓。\n",
      "-\n",
      "Input sentence: Your willingness to sacrifice countless late nights consoling them?\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 或者是因为你愿意花费无数的夜晚去安慰他们？\n",
      "-\n",
      "Input sentence: Callum: OK, we'll find out if you're right at the end of the programme.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: Callum：  OK，答案将会在节目的最后揭晓，到时我们再看你有没有答对。\n",
      "-\n",
      "Input sentence: When standing on a level surface, the hind feet are set back from under the body and the leg from pad to hock is at right angles to the ground.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 当他站在水平的地面上时，后足爪位于身躯后方（不在身躯正下方），从脚垫到飞节垂直于地面。\n",
      "-\n",
      "Input sentence: So who won? (Alaska doesn't count, you BOUGHT that state from Russia.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 所以到底是谁赢了？ 阿拉斯加不算数，那是你们从俄罗斯买的。\n",
      "-\n",
      "Input sentence: A Minneapolis couple decided to go to Florida to thaw out during a particularly icy winter.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 在一个特别寒冷的冬天，一对住在明尼阿波利斯市的夫妇决定去弗罗里达避寒。\n",
      "-\n",
      "Input sentence: Dumbledore, the lover of warm socks and sherbet lemons, creates soft, comfortable furniture.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 热爱温暖的毛袜子和冰冻柠檬汁的邓布利多，变出柔软舒适的家具。\n",
      "-\n",
      "Input sentence: To escape with a Ph.D., you must meaningfully extend the boundary of human knowledge.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 要成功拿到博士学位，你必须真正的扩展人类的知识边界。\n",
      "-\n",
      "Input sentence: Barry had been D.C.'s mayor for 12 years before he was put into prison for involvement with drugs in 1990.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 这人说：\"巴里在1990年由于涉及毒品而被关进监狱。 在这以前他在华盛顿担任了十二年的市长。\n",
      "-\n",
      "Input sentence: Phase out nankin/social security. It's not working and it's going to bankrupt the country.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 逐步淘汰社会保障。社会保障并不起作用，而且它会使我们的国家破产。\n",
      "-\n",
      "Input sentence: Daniel Radcliffe, who plays Harry, thanked all the fans who had turned up. \"If this doesn't get you exhilarated, nothing else will,\" he said.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 剧中哈里的饰演者丹尼尔·拉德克里夫对当天出席首映式的所有影迷表示了感谢，他说：“没有什么能比这更让你感到高兴的了。”\n",
      "-\n",
      "Input sentence: Look at these coasters over here.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 看看这边的杯垫。\n",
      "-\n",
      "Input sentence: It was tight. so ti lasted a long time .\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 两队不分胜负，所以持续了很长一段时间。\n",
      "-\n",
      "Input sentence: To use tone, press the YES button. You must use tone if you are setting up. the 2300 as a stand-alone stereo encoder.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 本帖隐藏的内容需要回复才可以浏览2300作为一个独立的立体声编码器。\n",
      "-\n",
      "Input sentence: Fuler is one of 253 schools have credited by the Sociation of Phiological schools in the United States and Canada.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 富勒是由美国和加拿大神学院联盟授权的253 家学院中的一员。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: It shows that vertical stiffener's spaces have some effects on pure-shearing ulti…\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 而腹板鼓曲对纯弯和纯剪极限承载力的影响则可不予考虑。\n",
      "-\n",
      "Input sentence: \"People are embarrassed to admit that's why they're giving up their pets, \" said Betsy McFarland, the Humane Society's director of communications for companion animals.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: “人们羞于说出他们遗弃宠物的真正原因，”人道协会陪伴动物协调主管伊莉莎白. 麦克法兰说。\n",
      "-\n",
      "Input sentence: Mars gets hit in this tutorial complete with monolith from 2001 Space Odyssey all in 2D.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 火星在本教程中获得击中从2001年太空漫游所有的一块完整的二维。\n",
      "-\n",
      "Input sentence: Show all articles on this topic.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 显示所有关于这个主题的文章。\n",
      "-\n",
      "Input sentence: Yesterday, a city with the husband and wife suffering from AIDS in the city hospital to get two of their 18-month-old daughter of the AIDS antibody test results of the report alone.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 昨天，我市一对同患艾滋病的夫妻在市二院拿到了他们18个月大女儿的艾滋病抗体检测结果报告单。\n",
      "-\n",
      "Input sentence: A model wearing a traditional Korean hanbok performs in a water tank at the \"Underwater Hanbok Fashion Show\" in Seoul, South Korea.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 首尔“水下韩服时装展”上，一名穿着古装韩服的模特在水箱内表演着，韩国。\n",
      "-\n",
      "Input sentence: Haven't found some hurt you when it is not pain, you pay attention to it begins to faint do painful.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 有些伤你没发现的时候它不疼，等你一注意它就开始隐隐做痛。\n",
      "-\n",
      "Input sentence: First of all, the term \"justice\" can have different interpretations in language. That is, a language can define different connotations for \"justice.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 首先，「正义」可能在同一语言区中即已出现各种不同的解释，亦即使用同样语言者都可能对「正义」有不同的内涵认定；\n",
      "-\n",
      "Input sentence: Standard Edition: for small-scale applications that require data caching and sharing clustered data.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 标准版：针对需要数据缓存和共享集群数据的小规模应用。\n",
      "-\n",
      "Input sentence: So basically our L/Cs are no different then other sight L/Cs.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 客户的意思是远期信用证吗？但是有不符合远期信用证的规定（银行利息由买方负责）\n",
      "-\n",
      "Input sentence: Through parameter calibration and model validation, model can be adapted to morphogenesis and LAI simulation for different varieties and management practice.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 通过对模型参数的校正和核实，使模型适应于不同类型品种的形态发生和LAI动态模拟。\n",
      "-\n",
      "Input sentence: NH3-N and concentration of particles reached lnd standard of sewage treatment plant.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 浓度和浊度达到国家一级排放标准。\n",
      "-\n",
      "Input sentence: Due to the high tonnage and large span of the whole steel space frame, process and fabrication of the steel space frame shall be strictly precise.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 由于整个钢网架的吨位重、跨度大，所以，对钢网架的加工制作精度方面要求非常严格。\n",
      "-\n",
      "Input sentence: As another example, the Japanese traditional \"soup\" (ie take a bath Church) is the mixing of men and women bath in some places so far, and often not prepared to foreigners, \"red in the face.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 再比如，日本传统的“汤”（即洗澡堂）是男女混浴的，有些地方至今如此，常让没有思想准备的外国人“面红耳赤”。\n",
      "-\n",
      "Input sentence: The theme ofWWIIwill always remain actual as the war will always be remembered by off-springs of those who won it.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 二战主题将会经久不衰，因为战胜一方的子孙后代将永远铭记这场战争。\n",
      "-\n",
      "Input sentence: No suspected cancer cells or cancer cells were found.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 宫颈刮片检查两组均未查见可疑癌细胞或癌细胞。\n",
      "-\n",
      "Input sentence: As our quotation is based on sea extra charge for dispatch by parcel post should be borne by buyers.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 咱们所报价钱是以海运为根基的。因此，因货品以邮包形式寄发而发生的所有分外花销应由买户承担。\n",
      "-\n",
      "Input sentence: Three bright spots , namely: China? Anping International Wire Mesh Fair, Anping international wire mesh Anping wire mesh industry base and the World.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 三大亮点，即：中国?安平国际丝网博览会、安平国际丝网产业基地和安平丝网大世界。\n",
      "-\n",
      "Input sentence: The ever-intensifying contradictions between economic development and resources and environment must be solved earnestly.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 经济发展与资源、环境的矛盾日益尖锐的情况亟待改变。\n",
      "-\n",
      "Input sentence: Still, who are we to say that we can stay?\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 然而，谁有敢说我们能长留此地？\n",
      "-\n",
      "Input sentence: Then, in analogy with the annealing of metals, the temperature is made high in the early stages of the process for faster minimisation or learning, then is reduced for greater stability.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 然后，与金属退火原理相类似，在开始阶段为了更快地最小化或学习，温度被升得很高，然后才（慢慢）降温以求稳定。\n",
      "-\n",
      "Input sentence: In these few years, the vehicle are rapidly increasing, the different parking are becoming more and more outstanding. The automatic parking system would provide a good way to set down the problems.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 近年来，随着机动车数量的急剧增长，国内许多城市停车难的问题越来越突出，而自动化立体车库的出现将为解决城市停车难的问题提供一个很好的方案。\n",
      "-\n",
      "Input sentence: Well my name is lee i am 30yrs my interest is movie, basketball, roller skating, shooting pool, bowling, music, & going on long walks in the park with my dog diamond.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 我的名字是李，今年30岁了，爱好是看电影，打篮球，溜旱冰，跳水，打保龄，听歌以及同我的狗宝石一起在公园散步。\n",
      "-\n",
      "Input sentence: He had formerly been in business at Bristol, but failed in debt to a number of people, compounded, and went to America.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 在那里他专心一志地做生意，在几年中就赚到许多钱。\n",
      "-\n",
      "Input sentence: Basing on the on site tests of anchor, authors found that anchors have obvious pre stress loss problem during stretching and locking, analyzed and proposed several solutions.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 根据对锚杆的现场测试，发现锚杆在张拉及锁定时存在显著的预应力损失问题，并对此进行了分析，提出了解决问题的几个办法。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: From hair tip first began gradually, after all, through from downward, nodular comb.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 先从发梢开始通顺，逐渐向上，打通全部结节后，从上向下梳顺。\n",
      "-\n",
      "Input sentence: The sky began to be clear up a bit when we left St Gallen abbey and library.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 离开圣加仑修道院和修道院图书馆，天稍稍开始放晴。\n",
      "-\n",
      "Input sentence: Once more, Cinderella's fairy godmother reminded her to be home by midnight.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 仙女教母再一次提醒辛德瑞拉要在午夜前到家。\n",
      "-\n",
      "Input sentence: This paper introduces the demand analysis and function design in detail, gives the source codes of relevant interface functions and base algorithm.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 本文详细介绍了它的需求分析和功能分析，并给出了相关接口函数和底层算法函数的实现源代码。\n",
      "-\n",
      "Input sentence: Manufacturer of thin and ultra-thin non-ferrous metal foils mainly made of copper, copper-alloys, nickel, genuine silver and nickel-silver.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 舒伦克超薄铜合金是制造超薄非铁合金箔为主的制造商。\n",
      "-\n",
      "Input sentence: All day thy wings have fann'd At that far height, the cold thin atmosphere: Yet stoop not, weary, to the welcome land, Though the dark night is near.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 你成天翕动翅膀， 任空气稀薄暴风寒冷，飞在高处， 疲乏中你不肯降落舒适的大地， 即使黑夜即将紧闭它的帷幕。\n",
      "-\n",
      "Input sentence: The two other attackers are believed to have tried to enter the terminal, which is protected by heavily armed police and X-ray machines.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 另外两名自杀手据信试图进入有武装警察和X光检测机保护的航站楼。\n",
      "-\n",
      "Input sentence: He became in legitimately through the door of the Law (vv. 1-3).\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 祂是合法地从律法的门进来的（1～3）；\n",
      "-\n",
      "Input sentence: The effect mechanism of laser biology was systemotically and deeply discussed in this artical, from 4 aspects:the light, electromagnetism field, heat and pressure effect of laser.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 本文对激光的生物学作用机制，从激光的光、电磁、热和压力效应四个方面进行了讨论。\n",
      "-\n",
      "Input sentence: The variant of FOXO3A associated with longevity is much more prevalent in 100-year-olds even than in 95-year-olds, which clearly demonstrates the value of studying the centenarian genome.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 与寿命相关的FOXO3A在百岁老人中即使与95岁老人相比也要普遍得多，这也清楚地显示出研究百岁老人基因组的价值所在。\n",
      "-\n",
      "Input sentence: Again, Uruguay are slight exception – they did start with a three-man defence.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 乌拉圭例外—他们一开始是个三后卫阵型。\n",
      "-\n",
      "Input sentence: Rugby' Seven People System origined from Scotland, it has special regularity and character.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 七人制橄榄球属于英式橄榄球，它具有独特的规律和特点。\n",
      "-\n",
      "Input sentence: This month you will be the darling of the media, so try to be a guest on TV and radio, or try for an interview or write-up on the Inte or in print.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 本月可能与媒体打道，所以测验考试作为电视或电台的嘉宾，或者为网络或最简单的面媒体采访和撰写。\n",
      "-\n",
      "Input sentence: So Isay to you that a novel must stand up to the adult tests of reality.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 所以我对你说，小说必须要成熟起来，能够让成年人将之放在生活中试验。\n",
      "-\n",
      "Input sentence: Yeah, like gentle breeze blowing through the cheeks, the hair dancing in the wind.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 是的，像微风吹过面颊，因为发梢在跳舞。\n",
      "-\n",
      "Input sentence: At present the direction of travel is not fully clear, but Theresa May's government has promised to set out a plan before triggering the EU's Article 50 divorce procedure.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 目前轨迹尚不清晰，但特雷莎·梅的政府承诺将在启动欧盟第50条脱欧程序之前制订一项计划。\n",
      "-\n",
      "Input sentence: Both the theoretical and experimental results have shown that there is a constant water level difference between the refined dynamic water level and the static one in the same well.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 理论分析和实验表明，改性动水位与同一井孔对应的静水位之间相差一恒定水位落差。\n",
      "-\n",
      "Input sentence: Otwoma believes the expense of generating nuclear energy could one day be met through shared regional projects but, until then, Kenya has to move forward on its own.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: Otwoma认为，核能发电的成本可能有朝一日通过共享的区域项目分担，但是在那之前肯尼亚需要自主前进。\n",
      "-\n",
      "Input sentence: On July 14, the Kremlin announced it will suspend participation in the Treaty on Conventional Forces in Europe, or CFE for short.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 7月14日，克里姆林宫宣布它将暂停参《与欧洲常规武器条约（CFE）》。\n",
      "-\n",
      "Input sentence: Outside-left. Made United debut at 17.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 左外锋，17岁就为曼联初次登场。\n",
      "-\n",
      "Input sentence: When the soul descends it divides itself creating a male and female half-soul.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 当灵魂下降并分离自己，创造了一个男性和女性的半个灵魂。\n",
      "-\n",
      "Input sentence: Axis symmetrical pure radial and pure shear vibrations were investigated theoretically for disk concentrators, whose thickness varying step-wise, linearly or exponentially with radial distance.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 理论上研究了盘形聚能器的轴对称纯径向振动和纯扭转振动。 所用盘形聚能器的厚度，沿半径按阶梯形，锥形和指数形变化。\n",
      "-\n",
      "Input sentence: The idea of flipping from one entry to another, following a line of inquiry (especially etymological inquiry) from one page to another, even one volume to another, is a sensual experience.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 想象一下从一个词条翻到另外一个词条，顺着线索（尤其是词源的查询）从一页翻到另一页，从这一卷翻到另外一卷，（绝对）是一种感官体验。\n",
      "-\n",
      "Input sentence: Further Practice for Pairs ·Add a third speaker and create your own lines.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 加进圈外人，创作你们自己的对话。\n",
      "-\n",
      "Input sentence: Still, Brasier asserts that the light carbon enrichments may well be able to form through lifeless chemical reactions—much as Fedo and others have argued could have occurred at Akilia.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 但伯拉西尔仍旧坚称，无生命的化学反应应该也可以聚集很多轻碳，这跟费多等人对阿基利亚的论辩很类似。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: The company is through ISO9001 quality system authentication , some products have also passed UL, CCEE authentication .\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 公司通过了ISO9001质量体系认证，部份产品还通过了UL、CCEE认证。\n",
      "-\n",
      "Input sentence: The Book of Revelation was also traditionally assigned to him.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 〈启示录〉传统上也认为是他的作品。\n",
      "-\n",
      "Input sentence: Our guest bedroom has an entire wall stacked with boxes containing unknown objects of more “stuff”.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 在我们的来宾卧室里，各种装着未知东西的箱子堆满了整堵墙。\n",
      "-\n",
      "Input sentence: It was easily good enough for pole so that was the main thing.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 那一圈跑得不错，足以使我获得杆位，那是最主要的。\n",
      "-\n",
      "Input sentence: This instrument uses the hardware structure taking 8031 chip-microprocessor as a main. It has functions of self-diagnosis, digital filtering and non-linear compensation etc.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 该仪器采用以8031单片机为核心的硬件结构，它具有自诊断、数字滤波和非线性补偿等功能。\n",
      "-\n",
      "Input sentence: While these space rocks don't exactly share our planet's orbit, they do cross it, in the sense that when they are closest to the sun, they are inside Earth's orbital path.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 虽然这些小行星并未和地球共享轨道，他们却实际上穿过了地球轨道，当他们靠近近日点的时候，他们则在地球绕日轨道内侧。\n",
      "-\n",
      "Input sentence: John has a windfall . It surprises his wife greatly .\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 约翰意外获得一笔财富，使他夫人大吃一惊。\n",
      "-\n",
      "Input sentence: So, the article researched the geography distribution of poets from 712AD to 805AD according to the fifteen Dao and analyzed the poets that existed in the same time and room.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 用唐代实行的行政规划十五道为基础，对公元712——805年诗人的地理分布进行全国性的分道研究，在时间、空间一定的前提下，对唐诗人进行定量、定性分析。\n",
      "-\n",
      "Input sentence: Yet he's ready to move on, knowing that \"the causes I care about have campaign-tested technology to work with.\"\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 然而他已经准备好了前行，他明白，“他所在意的那些已经经过了竞选活动的测试。”\n",
      "-\n",
      "Input sentence: Kandahar provincial official and his bodyguard on their way to work were shot dead by two gunmen on a motorbike.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 坎大哈省官员阿吉斯塔尼和他的保镖在上班的路上被两名骑摩托车的武装分子开枪打死。\n",
      "-\n",
      "Input sentence: We've rounded up some unusual ways to put your bottom-shelf vodka to good use all around your house.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 我们搜集了一些可以让你把箱底的伏特加应用到家里各个角落的小方法。\n",
      "-\n",
      "Input sentence: The target of anti_monopoly law should be to contain monopolizing behavior and various restrictive practices.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 反垄断法应以垄断和其他限制竞争行为作为规制对象；\n",
      "-\n",
      "Input sentence: To build a conservation-minded society, we should act at present for our future.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 构建节约型社会，是以现代的目光，着眼于长远的未来，是当务之急。\n",
      "-\n",
      "Input sentence: Large doses of carbs, sugar, and caffeine might keep you awake for a short time, but they will eventually lead to a \"crash, \" and have the opposite effect.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 大剂量的碳水化合物、糖和咖啡因会让你清醒一段时间，但是他们最终将导致一个觧“重磅睡眠”，产生相反的效果。\n",
      "-\n",
      "Input sentence: We desperately need a nation to exert some leadership, adopting policies to move promptly in that direction.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 我们急需一个国家发挥一定的领导作用，沿这一方向迅速采取措施。\n",
      "-\n",
      "Input sentence: Environmental records shall be stored and maintained in such a way that they are readily retrievable and protected against damage, deterioration or loss.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 对环境记录的保存和管理应使之便于查阅，避免损坏、变质或遗失。\n",
      "-\n",
      "Input sentence: He hastily composed another post, and then spent twenty minutes rephrasing it in a calmer tone, but a day later, when that message had also been deleted, his rage erupted.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 范老师急忙构思了又一条帖子，然后花了二十分钟时间把措辞改写得比较平和。 但是一天之后，这条留言又被删除了，这时范老师的愤怒爆发了。\n",
      "-\n",
      "Input sentence: Results(1)Determining the morbidity of hyperbilirubinemia; It put up an extremely remarkable difference comparing the antibody-released test result being positive group to the control group(P<0.01).\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 结果（1）抗体释放试验阳性患儿与对照组新生儿高胆红素血症发生率差异有统计学意义（P<0.01）。\n",
      "-\n",
      "Input sentence: All eastbound trains have been cancelled due to faulty signals.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 所有向东开去的火车由于信号错误而均被取消。\n",
      "-\n",
      "Input sentence: Taken into account the fact that aggregates absorb pitch, required abilities to resist high temperature track and penetration could be gained by controlling interspace ratio (4%).\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 考虑集料对沥青的吸收，用混合料的设计空隙率（4％）控制混合料的高温抗车辙能力与渗水性。\n",
      "-\n",
      "Input sentence: Unlike many of the other pirate-radio operators, who were in it mostly for money or adventure, Smedley saw his broadcasts as part of a wider moral crusade.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 许多海盗电台经营者常常都是为了金钱或冒险而入行，斯梅德利却与之不同，他将其广播事业视为广泛道德运动的一部分。\n",
      "-\n",
      "Input sentence: Ran Hua (1961 ~), female, associate professor, PhD. candidate , School of Journalism & Communication, Wuhan University, majoring in communication theories.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 冉华（1961～），女，武汉大学新闻与传播学院副教授，在职博士生，主要从事传播理论研究。\n",
      "-\n",
      "Input sentence: Others include shrouding Earth in sun-reflecting aerosol particles, manufacturing CO2-absorbing artificial trees, and pumping CO2 into underground reservoirs.\n",
      "Decoded sentence: 色列：为了我们的视来跟2福特别的 X                                                                                                       \n",
      "Correct sentence: 还有其它的计策，比如用具有反光效应的气溶胶粒子覆盖地球，或生产吸收二氧化碳的人工树木，还有把二氧化碳倒入地下水库的计策。\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # 抽取一个序列（训练集的一部分）进行解码。\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print('Correct sentence:', target_texts[seq_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98cf1ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a0ea603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2c26818e2b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a31359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f2cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90fc57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f5d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae383aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45e051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f7a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
